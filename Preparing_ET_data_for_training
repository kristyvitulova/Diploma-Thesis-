#imports
import numpy as np
import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from scipy.signal import stft
import matplotlib.pyplot as plt
import random
import glob
from scipy.stats import norm
from pycbc.waveform import get_td_waveform
from gwpy.timeseries import TimeSeries
from scipy.signal import spectrogram, welch, butter, filtfilt
from scipy.fftpack import fft, ifft
from scipy.signal import spectrogram
from scipy.signal.windows import tukey
from scipy.signal import welch, butter, filtfilt
from scipy.fft import fft, ifft, rfft, irfft, rfftfreq
from pycbc.waveform import get_td_waveform
from gwpy.timeseries import TimeSeries

# Check if GPU is available and set device
if not torch.cuda.is_available():
    print("No GPU available. Exiting...")
    sys.exit(1)
device = torch.device("cuda")
print(f"Running on device: {torch.cuda.get_device_name(0)}")

#generating ET noise
# === Nastavení ===
base_data_dir = "/home/kristyna/Desktop/Noise_final"
channel = "E1:STRAIN"
sample_rate = 8192
segment_duration = 2
segment_length = sample_rate * segment_duration

output_folder = "/home/kristyna/Desktop/ET_segments_waveforms_final"
os.makedirs(output_folder, exist_ok=True)
batch_size = 1000

# --- Whitening ---
def whiten(data, f_psd, psd, fs):
    psd = np.maximum(psd, 1e-20)
    freqs = np.fft.fftfreq(len(data), d=1/fs)
    psd_interp = np.interp(freqs, f_psd, psd)
    white_fft = np.fft.fft(data) / np.sqrt(psd_interp)
    return np.real(np.fft.ifft(white_fft))

# --- Načtení GWF souborů ---
gwf_files = []
for root, _, files in os.walk(base_data_dir):
    for file in sorted(files):
        if file.endswith(".gwf"):
            gwf_files.append(os.path.join(root, file))

print(f"Found {len(gwf_files)} .gwf files to process.")

# --- Zpracování ---
current_batch = []
batch_counter = 0

for idx, data_file in enumerate(gwf_files, 1):
    print(f"[{idx}/{len(gwf_files)}] Processing file: {data_file}")

    try:
        strain = TimeSeries.read(data_file, channel=channel)
        f_psd, psd = welch(strain.value, fs=sample_rate, nperseg=4096)
        num_segments = int((strain.times.value[-1] - strain.times.value[0]) // segment_duration)

        for i in range(num_segments):
            start = strain.times.value[0] + i * segment_duration
            end = start + segment_duration
            if end > strain.times.value[-1]:
                break

            segment = strain.crop(start, end).value
            segment = highpass_filter(segment)
            segment = whiten(segment, f_psd, psd, sample_rate)

            tensor = torch.tensor(segment, dtype=torch.float32).unsqueeze(0)  # [1, 8192]
            current_batch.append(tensor)

            if len(current_batch) >= batch_size:
                batch_tensor = torch.cat(current_batch, dim=0)  # [batch_size, 8192]
                save_path = os.path.join(output_folder, f"waveform_batch_{batch_counter:03d}.pt")
                torch.save(batch_tensor, save_path)
                print(f"Saved batch {batch_counter} with {len(current_batch)} waveform segments")
                batch_counter += 1
                current_batch = []

    except Exception as e:
        print(f"Error processing {data_file}: {e}")

# --- Uložit poslední batch ---
if current_batch:
    batch_tensor = torch.cat(current_batch, dim=0)
    save_path = os.path.join(output_folder, f"waveform_batch_{batch_counter:03d}.pt")
    torch.save(batch_tensor, save_path)
    print(f"Saved final batch {batch_counter} with {len(current_batch)} waveform segments")

print("Done.")
